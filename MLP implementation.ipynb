{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j37p1loPDE8R"
      },
      "outputs": [],
      "source": [
        "#initialize random number Generator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from math import exp\n",
        "import random\n",
        "#initialize random number gernerator\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Calss Neuron**"
      ],
      "metadata": {
        "id": "mpRnDieTu06p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Neuron:\n",
        "    def __init__(self, num_inputs, activation_function):\n",
        "        # Initialize weights and store them\n",
        "        self.bias = np.random.uniform(-2.0, 2.0)  # Bias term initialized randomly between -2.0 and 2.0\n",
        "        self.weights = [np.random.uniform(-2.0, 2.0) for _ in range(num_inputs)]  # Weights initialized randomly for each input\n",
        "        self.activation_function = activation_function  # Activation function as a string (e.g., 'logist', 'tanh', 'id')\n",
        "\n",
        "        # Variables needed for training the network\n",
        "        # Δw = n * delta * out\n",
        "        # delta = (y' - y) * f'(net) for output layer\n",
        "        # delta = (∑ delta * w) * f'(net) for hidden layers\n",
        "        self.delta = 0  # Error signal for backpropagation\n",
        "        self.weighted_sum = 0  # Net input to the neuron\n",
        "        self.out = 0  # Output of the neuron after activation\n",
        "        self.out_deriv = 0  # Derivative of the output (used in backpropagation)\n",
        "\n",
        "    def activate(self, inputs):\n",
        "        # Calculate the weighted sum of the input vector plus the bias term\n",
        "        self.weighted_sum = sum([w * x for (w, x) in zip(self.weights, inputs)]) + self.bias\n",
        "\n",
        "        # Apply the activation function and return the output value\n",
        "        if self.activation_function == \"logist\":\n",
        "            # Logistic (sigmoid) function: 1 / (1 + e^(-weighted_sum))\n",
        "            self.out = 1 / (1 + exp(-self.weighted_sum))\n",
        "            return self.out\n",
        "        elif self.activation_function == \"tanh\":\n",
        "            # Tanh function: (e^x - e^(-x)) / (e^x + e^(-x))\n",
        "            self.out = (exp(self.weighted_sum) - exp(-self.weighted_sum)) / (exp(self.weighted_sum) + exp(-self.weighted_sum))\n",
        "            return self.out\n",
        "        elif self.activation_function == \"id\":\n",
        "            # Identity function: returns the weighted sum as is\n",
        "            self.out = self.weighted_sum\n",
        "            return self.out\n",
        "        else:\n",
        "            # Raise an error if an unknown activation function is provided\n",
        "            raise ValueError(\"Unknown activation function\")\n"
      ],
      "metadata": {
        "id": "E394qFfDG3fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Class Layer**\n",
        "\n"
      ],
      "metadata": {
        "id": "RceTPe6ju_gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self, num_neurons, num_inputs, activation_function):\n",
        "        # Raise an error if the number of neurons in a layer is not valid\n",
        "        if num_neurons > 1000 or num_neurons < 1:\n",
        "            raise ValueError(\"Number of neurons should be between 1 and 1000\")\n",
        "        # Initialize neurons in the layer and store them in a list\n",
        "        self.neurons = [Neuron(num_inputs, activation_function) for _ in range(num_neurons)]\n",
        "\n",
        "    def feed_forward(self, inputs):\n",
        "        # Pass inputs through each neuron and return their outputs\n",
        "        return [neuron.activate(inputs) for neuron in self.neurons]"
      ],
      "metadata": {
        "id": "h52BILsKTxvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Class MLP**\n"
      ],
      "metadata": {
        "id": "EKDUPdSVvEU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, num_neurons, num_inputs, activation_functions):\n",
        "        # Check if the length of activation_functions matches the number of layers\n",
        "        if len(num_neurons) != len(activation_functions):\n",
        "            raise ValueError(\"The number of activation functions must match the number of layers.\")\n",
        "\n",
        "        # Initialize the number of inputs for each layer\n",
        "        num_inputs_per_layer = [num_inputs] + num_neurons[:-1]\n",
        "\n",
        "        # Initialize each layer with the corresponding number of neurons, inputs, and activation function\n",
        "        self.layers = [Layer(num_neurons, num_inputs, activation_function)\n",
        "                       for num_neurons, num_inputs, activation_function in zip(num_neurons, num_inputs_per_layer, activation_functions)]\n",
        "\n",
        "    def predict(self, vec):\n",
        "        # Forward pass through each layer until the output layer\n",
        "        x = vec  # Initialize input vector\n",
        "        for layer in self.layers:\n",
        "            x = layer.feed_forward(x)  # Pass output from one layer to the next\n",
        "        return x  # Return final output from the last layer\n",
        "\n"
      ],
      "metadata": {
        "id": "rVHhR4KogdGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Backpropagation Of Error**"
      ],
      "metadata": {
        "id": "DXJhSNU_Wy4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Backpropagation of Error Algorithm\n",
        "\n",
        "def backpropagation_step(mlp, vec, learning_rate_of_each_layer):\n",
        "    # Forward pass to get the prediction\n",
        "    y = mlp.predict(vec[0])\n",
        "\n",
        "    # Calculate deltas in the output layer\n",
        "    for i in range(len(mlp.layers[-1].neurons)):\n",
        "        neuron = mlp.layers[-1].neurons[i]\n",
        "\n",
        "        # Calculate derivative of activation function for the output neuron\n",
        "        if neuron.activation_function == \"logist\":\n",
        "            f_net_deriv = neuron.out * (1 - neuron.out)  # Derivative of sigmoid function\n",
        "        elif neuron.activation_function == \"tanh\":\n",
        "            f_net_deriv = 1 - neuron.out ** 2  # Derivative of tanh function\n",
        "        else:\n",
        "            f_net_deriv = 1\n",
        "\n",
        "        # Calculate delta for the output neuron\n",
        "        neuron.delta = (vec[1][i] - y[i]) * f_net_deriv\n",
        "\n",
        "        # Update weights and bias for the output neuron\n",
        "        for w in range(len(neuron.weights)):\n",
        "            neuron.weights[w] += learning_rate_of_each_layer[-1] * neuron.delta * mlp.layers[-2].neurons[w].out\n",
        "        neuron.bias += learning_rate_of_each_layer[-1] * neuron.delta\n",
        "\n",
        "    # Calculate deltas for hidden layers\n",
        "    for i in range(len(mlp.layers) - 2, 0, -1):\n",
        "        for index, neuron in enumerate(mlp.layers[i - 1].neurons):\n",
        "            # Calculate derivative of activation function for the hidden neuron\n",
        "            if neuron.activation_function == \"logist\":\n",
        "                f_net_deriv = neuron.out * (1 - neuron.out)  # Derivative of sigmoid function\n",
        "            elif neuron.activation_function == \"tanh\":\n",
        "                f_net_deriv = 1 - neuron.out ** 2  # Derivative of tanh function\n",
        "            else:\n",
        "                f_net_deriv = 1\n",
        "\n",
        "            # Calculate delta for the hidden neuron\n",
        "            neuron.delta = sum(\n",
        "                [next_neuron.delta * next_neuron.weights[index] for next_neuron in mlp.layers[i + 1].neurons]\n",
        "            ) * f_net_deriv\n",
        "\n",
        "            # Update weights and bias for the hidden neuron\n",
        "            for w in range(len(neuron.weights)):\n",
        "                neuron.weights[w] += learning_rate_of_each_layer[i] * neuron.delta * mlp.layers[i - 1].neurons[w].out\n",
        "            neuron.bias += learning_rate_of_each_layer[i] * neuron.delta\n",
        "\n",
        "    # Update the first layer\n",
        "    for index, neuron in enumerate(mlp.layers[0].neurons):\n",
        "        # Calculate derivative of activation function for the first layer neuron\n",
        "        if neuron.activation_function == \"logist\":\n",
        "            f_net_deriv = neuron.out * (1 - neuron.out)  # Derivative of sigmoid function\n",
        "        elif neuron.activation_function == \"tanh\":\n",
        "            f_net_deriv = 1 - neuron.out ** 2  # Derivative of tanh function\n",
        "        else:\n",
        "            f_net_deriv = 1\n",
        "\n",
        "        # Calculate delta for the first layer neuron\n",
        "        neuron.delta = sum(\n",
        "            [next_neuron.delta * next_neuron.weights[index] for next_neuron in mlp.layers[1].neurons]\n",
        "        ) * f_net_deriv\n",
        "\n",
        "        # Update weights and bias for the first layer neuron\n",
        "        for w in range(len(neuron.weights)):\n",
        "            neuron.weights[w] += learning_rate_of_each_layer[0] * neuron.delta * vec[0][w]\n",
        "        neuron.bias += learning_rate_of_each_layer[0] * neuron.delta\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Training function\n",
        "def backpropagation(mlp, number_of_iterations, train_data, learning_rate_of_each_layer):\n",
        "    error_list = []\n",
        "\n",
        "    # Iterate through the number of training iterations\n",
        "    for iteration in range(number_of_iterations):\n",
        "        total_error = 0\n",
        "\n",
        "        # Iterate over each training data point\n",
        "        for data in train_data:\n",
        "            # Perform a backpropagation step for the given data\n",
        "            backpropagation_step(mlp, [data[:-1], [data[-1]]], learning_rate_of_each_layer)\n",
        "\n",
        "            # Calculate the error for the prediction\n",
        "            predicted_output = mlp.predict(data[:-1])\n",
        "            total_error += sum([(predicted_output[i] - data[-1]) ** 2 for i in range(len(predicted_output))])\n",
        "\n",
        "        # Append the average error for this iteration\n",
        "        error_list.append(total_error / len(train_data))\n",
        "\n",
        "        # Print the error for each iteration (optional, for debugging)\n",
        "        # print(f\"Iteration {iteration + 1}, Error: {total_error / len(train_data)}\")\n",
        "\n",
        "    # Save learning curve to file\n",
        "    with open(\"learning_curve.txt\", \"w\") as f:\n",
        "        for i, error in enumerate(error_list):\n",
        "            f.write(f\"{i + 1} {error}\\n\")\n",
        "\n",
        "    # Visualize the learning curve\n",
        "    plt.plot(range(1, number_of_iterations + 1), error_list)\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Error')\n",
        "    plt.title('Learning Curve')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "jMMksfQYXSL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Pre-processing**\n",
        "\n"
      ],
      "metadata": {
        "id": "A_G0WdzkkrDX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an empty list to hold the 2D list structure\n",
        "training_data = []\n",
        "\n",
        "# Open the file and read it line by line\n",
        "with open('/content/sample_data/PA-A_training_data_04.txt') as file:\n",
        "    for line in file:\n",
        "        # Split each line by whitespace and convert it to a list of values\n",
        "        values = line.split()\n",
        "        # Append the parsed values to the main list\n",
        "        training_data.append(values)\n",
        "\n",
        "# Skip the first four rows (assuming these are header rows)\n",
        "training_data = training_data[4:]\n",
        "\n",
        "# Convert all elements to float\n",
        "for i in range(len(training_data)):\n",
        "    for j in range(len(training_data[i])):\n",
        "        training_data[i][j] = float(training_data[i][j])\n",
        "\n",
        "# Print the processed training data\n",
        "print(training_data)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "# Set the desired split ratio (80% training, 20% testing)\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(training_data) * split_ratio)\n",
        "\n",
        "# Shuffle the data to ensure randomness\n",
        "random.shuffle(training_data)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data = training_data[:split_index]\n",
        "test_data = training_data[split_index:]\n",
        "\n",
        "# Separate features and labels for the training set\n",
        "train = []\n",
        "for data in train_data:\n",
        "    train.append(data[:-1])  # Append features (all except the last element)\n",
        "    train.append([data[-1]])  # Append label (last element)\n",
        "\n",
        "# Separate features and labels for the test set\n",
        "test = []\n",
        "for data in test_data:\n",
        "    test.append(data[:-1])  # Append features (all except the last element)\n",
        "    test.append([data[-1]])  # Append label (last element)\n"
      ],
      "metadata": {
        "id": "2eWzymd3Q13Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dafe4cbc-29a7-49dc-aad1-145154389ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.91919, -1.0, 0.550063], [-1.87879, -1.0, 0.552135], [-1.47475, -1.0, 0.469293], [-1.43434, -1.0, 0.451852], [-1.39394, -1.0, 0.433109], [-1.15152, -1.0, 0.300662], [-1.11111, -1.0, 0.276604], [-1.07071, -1.0, 0.252388], [-1.0303, -1.0, 0.228172], [-0.989899, -1.0, 0.204114], [-0.949495, -1.0, 0.180372], [-0.909091, -1.0, 0.157101], [-0.666667, -1.0, 0.0355155], [-0.10101, -1.0, -0.0273895], [-0.0606061, -1.0, -0.0177471], [-0.020202, -1.0, -0.00634131], [0.020202, -1.0, 0.00675336], [0.0606061, -1.0, 0.0214515], [0.10101, -1.0, 0.0376572], [0.141414, -1.0, 0.0552646], [0.181818, -1.0, 0.0741589], [0.222222, -1.0, 0.0942167], [0.262626, -1.0, 0.115307], [0.30303, -1.0, 0.137293], [0.343434, -1.0, 0.16003], [0.666667, -1.0, 0.3506], [0.707071, -1.0, 0.373163], [0.747475, -1.0, 0.394937], [0.787879, -1.0, 0.415782], [0.828283, -1.0, 0.435561], [0.868687, -1.0, 0.454145], [0.909091, -1.0, 0.471413], [0.949495, -1.0, 0.487251], [0.989899, -1.0, 0.501557], [1.0303, -1.0, 0.514237], [1.07071, -1.0, 0.525208], [1.31313, -1.0, 0.55198], [1.35354, -1.0, 0.54966], [1.39394, -1.0, 0.5454], [1.43434, -1.0, 0.539229], [1.63636, -1.0, 0.48152], [1.83838, -1.0, 0.386921], [1.87879, -1.0, 0.364836], [1.91919, -1.0, 0.342017], [1.9596, -1.0, 0.318613], [2.0, -1.0, 0.294777], [-2.0, -0.666667, 0.485197], [-1.9596, -0.666667, 0.483113], [-1.91919, -0.666667, 0.479086], [-1.87879, -0.666667, 0.473143], [-1.83838, -0.666667, 0.465322], [-1.79798, -0.666667, 0.455676], [-1.75758, -0.666667, 0.444266], [-1.71717, -0.666667, 0.431168], [-1.67677, -0.666667, 0.416467], [-1.15152, -0.666667, 0.134196], [-1.11111, -0.666667, 0.110504], [-1.07071, -0.666667, 0.0873019], [-1.0303, -0.666667, 0.0647407], [-0.868687, -0.666667, -0.0162326], [-0.828283, -0.666667, -0.0334969], [-0.787879, -0.666667, -0.049332], [-0.747475, -0.666667, -0.0636343], [-0.505051, -0.666667, -0.112806], [-0.464646, -0.666667, -0.114394], [-0.424242, -0.666667, -0.114025], [-0.383838, -0.666667, -0.1117], [-0.343434, -0.666667, -0.107437], [-0.30303, -0.666667, -0.101261], [-0.262626, -0.666667, -0.0932132], [-0.222222, -0.666667, -0.0833467], [0.020202, -0.666667, 0.00967472], [0.0606061, -0.666667, 0.0298689], [0.10101, -0.666667, 0.0510789], [0.141414, -0.666667, 0.0731663], [0.181818, -0.666667, 0.0959868], [0.222222, -0.666667, 0.119392], [0.262626, -0.666667, 0.143228], [0.30303, -0.666667, 0.16734], [0.343434, -0.666667, 0.191571], [0.383838, -0.666667, 0.215762], [0.424242, -0.666667, 0.239756], [0.464646, -0.666667, 0.263396], [0.505051, -0.666667, 0.286528], [0.545455, -0.666667, 0.309], [0.787879, -0.666667, 0.422195], [0.828283, -0.666667, 0.436302], [0.989899, -0.666667, 0.475607], [1.0303, -0.666667, 0.480831], [1.07071, -0.666667, 0.484128], [1.11111, -0.666667, 0.485476], [1.83838, -0.666667, 0.224845], [1.87879, -0.666667, 0.20071], [1.91919, -0.666667, 0.176475], [1.9596, -0.666667, 0.152299], [2.0, -0.666667, 0.128341], [-2.0, -0.333333, 0.376863], [-1.9596, -0.333333, 0.366992], [-1.91919, -0.333333, 0.355367], [-1.87879, -0.333333, 0.342064], [-1.83838, -0.333333, 0.327168], [-1.47475, -0.333333, 0.140388], [-1.43434, -0.333333, 0.116276], [-1.39394, -0.333333, 0.0920447], [-1.23232, -0.333333, -0.00290887], [-1.19192, -0.333333, -0.0253795], [-1.15152, -0.333333, -0.0470439], [-1.11111, -0.333333, -0.0677607], [-1.07071, -0.333333, -0.0873946], [-1.0303, -0.333333, -0.105818], [-0.989899, -0.333333, -0.122909], [-0.949495, -0.333333, -0.138558], [-0.909091, -0.333333, -0.152662], [-0.707071, -0.333333, -0.197171], [-0.666667, -0.333333, -0.200464], [-0.464646, -0.333333, -0.187709], [-0.424242, -0.333333, -0.179431], [-0.222222, -0.333333, -0.112351], [-0.181818, -0.333333, -0.0944107], [-0.141414, -0.333333, -0.0752137], [-0.10101, -0.333333, -0.0548851], [-0.0606061, -0.333333, -0.0335578], [-0.020202, -0.333333, -0.0113708], [0.020202, -0.333333, 0.011531], [0.0606061, -0.333333, 0.0349982], [0.10101, -0.333333, 0.0588776], [0.141414, -0.333333, 0.0830133], [0.181818, -0.333333, 0.107248], [0.222222, -0.333333, 0.131423], [0.262626, -0.333333, 0.155381], [0.30303, -0.333333, 0.178966], [0.343434, -0.333333, 0.202023], [0.666667, -0.333333, 0.3506], [0.949495, -0.333333, 0.398154], [0.989899, -0.333333, 0.3973], [1.0303, -0.333333, 0.394493], [1.27273, -0.333333, 0.33855], [1.31313, -0.333333, 0.323278], [1.35354, -0.333333, 0.306537], [1.39394, -0.333333, 0.288436], [1.67677, -0.333333, 0.134486], [1.71717, -0.333333, 0.11033], [1.75758, -0.333333, 0.086094], [1.79798, -0.333333, 0.0619369], [1.83838, -0.333333, 0.0380162], [1.87879, -0.333333, 0.014488], [1.91919, -0.333333, -0.00849408], [1.9596, -0.333333, -0.0307801], [2.0, -0.333333, -0.0522247], [-2.0, 0.0, 0.227041], [-1.9596, 0.0, 0.210471], [-1.91919, 0.0, 0.192528], [-1.43434, 0.0, -0.0808592], [-1.39394, 0.0, -0.103915], [-1.35354, 0.0, -0.126293], [-1.15152, 0.0, -0.223105], [-1.11111, 0.0, -0.238566], [-1.07071, 0.0, -0.25247], [-1.0303, 0.0, -0.264727], [-0.989899, 0.0, -0.275255], [-0.424242, 0.0, -0.225084], [-0.383838, 0.0, -0.20834], [-0.343434, 0.0, -0.190236], [-0.0606061, 0.0, -0.0362747], [-0.020202, 0.0, -0.0121179], [0.020202, 0.0, 0.0121179], [0.0606061, 0.0, 0.0362747], [0.10101, 0.0, 0.0601947], [0.141414, 0.0, 0.0837218], [0.181818, 0.0, 0.106703], [0.222222, 0.0, 0.128987], [0.262626, 0.0, 0.150429], [0.30303, 0.0, 0.17089], [0.343434, 0.0, 0.190236], [0.424242, 0.0, 0.225084], [0.464646, 0.0, 0.240359], [0.505051, 0.0, 0.254066], [0.545455, 0.0, 0.266114], [0.787879, 0.0, 0.299996], [0.909091, 0.0, 0.290867], [1.83838, 0.0, -0.152997], [1.87879, 0.0, -0.173328], [1.91919, 0.0, -0.192528], [1.9596, 0.0, -0.210471], [2.0, 0.0, -0.227041], [-2.0, 0.333333, 0.0522247], [-1.55556, 0.333333, -0.204911], [-1.51515, 0.333333, -0.227194], [-1.47475, 0.333333, -0.248634], [-1.43434, 0.333333, -0.269093], [-1.39394, 0.333333, -0.288436], [-0.464646, 0.333333, -0.266549], [-0.424242, 0.333333, -0.245958], [-0.262626, 0.333333, -0.155381], [-0.222222, 0.333333, -0.131423], [-0.10101, 0.333333, -0.0588776], [-0.0606061, 0.333333, -0.0349982], [-0.020202, 0.333333, -0.011531], [0.020202, 0.333333, 0.0113708], [0.181818, 0.333333, 0.0944107], [0.222222, 0.333333, 0.112351], [1.23232, 0.333333, 0.00290887], [1.27273, 0.333333, -0.0202214], [1.31313, 0.333333, -0.0438603], [2.0, 0.333333, -0.376863], [-2.0, 0.666667, -0.128341], [-1.9596, 0.666667, -0.152299], [-1.91919, 0.666667, -0.176475], [-1.87879, 0.666667, -0.20071], [-1.83838, 0.666667, -0.224845], [-1.79798, 0.666667, -0.248724], [-0.828283, 0.666667, -0.436302], [-0.666667, 0.666667, -0.371022], [-0.585859, 0.666667, -0.330666], [-0.545455, 0.666667, -0.309], [-0.505051, 0.666667, -0.286528], [-0.464646, 0.666667, -0.263396], [-0.343434, 0.666667, -0.191571], [-0.30303, 0.666667, -0.16734], [0.10101, 0.666667, 0.0435335], [0.626263, 0.666667, 0.0964656], [0.666667, 0.666667, 0.0872783], [0.707071, 0.666667, 0.0763107], [1.67677, 0.666667, -0.416467], [1.71717, 0.666667, -0.431168], [1.87879, 0.666667, -0.473143], [1.91919, 0.666667, -0.479086], [1.9596, 0.666667, -0.483113], [2.0, 0.666667, -0.485197], [-2.0, 1.0, -0.294777], [-1.9596, 1.0, -0.318613], [-1.91919, 1.0, -0.342017], [-1.87879, 1.0, -0.364836], [-1.83838, 1.0, -0.386921], [-1.79798, 1.0, -0.408129], [-1.75758, 1.0, -0.428321], [-1.15152, 1.0, -0.541751], [-1.11111, 1.0, -0.5344], [-1.07071, 1.0, -0.525208], [-1.0303, 1.0, -0.514237], [-0.989899, 1.0, -0.501557], [-0.949495, 1.0, -0.487251], [-0.909091, 1.0, -0.471413], [-0.868687, 1.0, -0.454145], [-0.828283, 1.0, -0.435561], [-0.787879, 1.0, -0.415782], [-0.545455, 1.0, -0.279676], [-0.505051, 1.0, -0.255472], [-0.464646, 1.0, -0.231247], [-0.424242, 1.0, -0.20716], [-0.383838, 1.0, -0.18337], [0.30303, 1.0, 0.0473722], [0.343434, 1.0, 0.0455401], [0.949495, 1.0, -0.180372], [0.989899, 1.0, -0.204114], [1.79798, 1.0, -0.55041], [1.83838, 1.0, -0.552251], [1.87879, 1.0, -0.552135], [1.91919, 1.0, -0.550063], [1.9596, 1.0, -0.546049], [2.0, 1.0, -0.540119], [-2.0, 1.33333, -0.428763], [-1.9596, 1.33333, -0.449851], [-1.91919, 1.33333, -0.469907], [-1.87879, 1.33333, -0.488798], [-1.75758, 1.33333, -0.5373], [-1.71717, 1.33333, -0.550391], [-0.10101, 1.33333, -0.0200899], [-0.0606061, 1.33333, -0.0106726], [-0.020202, 1.33333, -0.00308856], [0.020202, 1.33333, 0.00261262], [0.0606061, 1.33333, 0.00639377], [0.10101, 1.33333, 0.00823022], [0.141414, 1.33333, 0.00810998], [0.262626, 1.33333, -0.00391928], [0.30303, 1.33333, -0.0117313], [0.383838, 1.33333, -0.0327717], [0.989899, 1.33333, -0.342791], [1.0303, 1.33333, -0.366484], [1.07071, 1.33333, -0.389689], [1.15152, 1.33333, -0.43403], [1.83838, 1.33333, -0.578384], [1.87879, 1.33333, -0.570345], [1.91919, 1.33333, -0.560487], [1.9596, 1.33333, -0.548873], [2.0, 1.33333, -0.53558], [-2.0, 1.66667, -0.515548], [-1.9596, 1.66667, -0.531568], [-1.43434, 1.66667, -0.578453], [-1.39394, 1.66667, -0.568811], [-1.15152, 1.66667, -0.476905], [-1.11111, 1.66667, -0.456847], [-1.07071, 1.66667, -0.435757], [-1.0303, 1.66667, -0.413771], [-0.989899, 1.66667, -0.391034], [-0.949495, 1.66667, -0.367694], [-0.747475, 1.66667, -0.24736], [-0.707071, 1.66667, -0.223667], [-0.141414, 1.66667, -0.00385012], [-0.10101, 1.66667, -0.00031097], [-0.0606061, 1.66667, 0.00128129], [-0.020202, 1.66667, 0.000916254], [0.020202, 1.66667, -0.00140369], [0.0606061, 1.66667, -0.00566339], [0.222222, 1.66667, -0.0413583], [0.262626, 1.66667, -0.0546547], [0.383838, 1.66667, -0.103699], [0.989899, 1.66667, -0.443731], [1.0303, 1.66667, -0.464452], [1.07071, 1.66667, -0.484091], [1.11111, 1.66667, -0.50252], [1.15152, 1.66667, -0.519618], [1.19192, 1.66667, -0.535273], [1.23232, 1.66667, -0.549384], [1.51515, 1.66667, -0.598587], [1.79798, 1.66667, -0.554343], [1.83838, 1.66667, -0.540846], [1.87879, 1.66667, -0.525768], [1.91919, 1.66667, -0.509208], [1.9596, 1.66667, -0.491274], [2.0, 1.66667, -0.472082], [-2.0, 2.0, -0.545578], [-1.9596, 2.0, -0.554766], [-1.91919, 2.0, -0.562113], [-1.63636, 2.0, -0.559561], [-1.0303, 2.0, -0.29096], [-0.989899, 2.0, -0.266729], [-0.949495, 2.0, -0.242538], [-0.909091, 2.0, -0.218544], [-0.626263, 2.0, -0.0688526], [-0.585859, 2.0, -0.0517578], [-0.020202, 2.0, 0.0048202], [0.0606061, 2.0, -0.0170971], [0.10101, 2.0, -0.0305975], [0.141414, 2.0, -0.0456785], [0.181818, 2.0, -0.0622417], [0.383838, 2.0, -0.16321], [0.424242, 2.0, -0.186111], [0.464646, 2.0, -0.209577], [0.909091, 2.0, -0.46063], [0.949495, 2.0, -0.478899], [0.989899, 2.0, -0.495822], [1.0303, 2.0, -0.51129], [1.07071, 2.0, -0.525202], [1.39394, 2.0, -0.571935], [1.91919, 2.0, -0.401873], [1.9596, 2.0, -0.379592], [2.0, 2.0, -0.356614]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MLP Example**"
      ],
      "metadata": {
        "id": "A-uo3lbTk8VA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example MLP configuration\n",
        "num_neurons = [2,3,3,1]  # Number of neurons in each layer\n",
        "num_inputs = 2  # Number of inputs to the first layer\n",
        "activation_functions = [ \"tanh\",\"tanh\",\"tanh\",\"tanh\"]  # Activation functions for each layer\n",
        "\n",
        "mlp = MLP(num_neurons, num_inputs, activation_functions)\n",
        "\n"
      ],
      "metadata": {
        "id": "shhe0jRtA3XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Test the code**"
      ],
      "metadata": {
        "id": "MiGmBmoTlJp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "backpropagation(mlp,1000,train_data,[0.01,0.01,0.01,0.01])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "IgbaNMLelkj5",
        "outputId": "9844dc54-740e-4e02-a6cd-6cd4d15d4f2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_mlp(mlp, test_data):\n",
        "    total_error = 0\n",
        "    correct_predictions = 0\n",
        "    predictions = []\n",
        "\n",
        "    # Iterate over each test data point\n",
        "    for data in test_data:\n",
        "        # Perform a forward pass to get the prediction\n",
        "        predicted_output = mlp.predict(data[:-1])\n",
        "        predictions.append(predicted_output)\n",
        "\n",
        "        # Calculate the error for the prediction\n",
        "        error = sum([(predicted_output[i] - data[-1]) ** 2 for i in range(len(predicted_output))])\n",
        "        total_error += error\n",
        "\n",
        "    # Calculate average error across all test samples\n",
        "    avg_error = total_error / len(test_data)\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Average Error on Test Set: {avg_error}\")\n",
        "\n",
        "    # Return predictions and average error\n",
        "    return predictions, avg_error\n",
        "\n",
        "\n",
        "# Run the test function on the test data\n",
        "predictions, avg_error = test_mlp(mlp, test_data)\n",
        "\n",
        "# Print predictions for analysis\n"
      ],
      "metadata": {
        "id": "l3LCk5cDtC9H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37b2001-1eb4-4959-a6f3-e07ace8ab289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Error on Test Set: 0.04216846730675933\n"
          ]
        }
      ]
    }
  ]
}